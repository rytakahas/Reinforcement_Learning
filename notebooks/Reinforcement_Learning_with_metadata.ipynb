{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmIWsSHOEPCT"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1DBiEoUHc7YftJdDkbJaEc3-BOE5BCwNR\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122419,
     "status": "ok",
     "timestamp": 1739989942547,
     "user": {
      "displayName": "Ryoji Takahashi",
      "userId": "08099237406056068712"
     },
     "user_tz": -60
    },
    "id": "KgNlptvkO2mR",
    "outputId": "8784c392-50f9-4b84-cbfd-79d122bf7dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "The following additional packages will be installed:\n",
      "  swig4.0\n",
      "Suggested packages:\n",
      "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  swig swig4.0\n",
      "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
      "Need to get 1,116 kB of archives.\n",
      "After this operation, 5,542 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
      "Fetched 1,116 kB in 0s (3,258 kB/s)\n",
      "Selecting previously unselected package swig4.0.\n",
      "(Reading database ... 124926 files and directories currently installed.)\n",
      "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
      "Unpacking swig (4.0.2-1ubuntu1) ...\n",
      "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Setting up swig (4.0.2-1ubuntu1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "\u001b[33mWARNING: Skipping box2d-py as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
      "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting swig==4.* (from gymnasium[box2d])\n",
      "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2351181 sha256=8022666e1c52ef9c7a4bcb55a7b4efd0270560cf812fdfe933886e070476cb72\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: swig, box2d-py\n",
      "Successfully installed box2d-py-2.3.5 swig-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y swig cmake ffmpeg\n",
    "!pip uninstall -y box2d-py\n",
    "!pip install gymnasium[box2d] pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGNkpnZaEsbY",
    "outputId": "6a75a147-0684-4b91-a1ba-88f4546eaf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# ✅ Colab Notebook Setup for Reinforcement Learning (DQN, PPO) with GPU Support\n",
    "\n",
    "# Install required dependencies\n",
    "!pip install stable-baselines3 torch pandas numpy requests matplotlib seaborn -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# ✅ Load Metadata (Building Characteristics)\n",
    "METADATA_URL = \"https://media.githubusercontent.com/media/buds-lab/building-data-genome-project-2/refs/heads/master/data/metadata/metadata.csv\"\n",
    "response = requests.get(METADATA_URL)\n",
    "metadata_df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# ✅ Load Energy Dataset\n",
    "ENERGY_DATA_URL = \"https://github.com/buds-lab/building-data-genome-project-2/raw/master/data/meters/kaggle/kaggle.csv\"\n",
    "response = requests.get(ENERGY_DATA_URL)\n",
    "energy_df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# ✅ Convert Metadata 'building_id' to match Energy Dataset\n",
    "metadata_mapping = {name: idx for idx, name in enumerate(metadata_df[\"building_id\"].unique())}\n",
    "metadata_df[\"building_id\"] = metadata_df[\"building_id\"].map(metadata_mapping)\n",
    "energy_df[\"building_id\"] = energy_df[\"building_id\"].astype(int)  # Ensure integer format\n",
    "\n",
    "# ✅ Merge Energy Data with Metadata\n",
    "df = energy_df.merge(metadata_df, on=\"building_id\", how=\"left\")\n",
    "\n",
    "# ✅ Select Relevant Features\n",
    "df = df[[\"building_id\", \"meter\", \"meter_reading\", \"sqm\", \"numberoffloors\", \"yearbuilt\", \"eui\"]]\n",
    "\n",
    "# ✅ Fill Missing Values\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1635"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_df[\"building_id\"] = energy_df[\"building_id\"].astype(int)  # Ensure integer format\n",
    "metadata_df['building_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-BPDJ1vzIDtb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ryoji/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ryoji/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAB Accuracy: 0.9500\n",
      "MAB Precision: 1.0000\n",
      "MAB Recall: 0.9500\n",
      "MAB F1 Score: 0.9744\n",
      "MAB NDCG Score: 1.0000\n",
      "\n",
      "MDP Accuracy: 0.1500\n",
      "MDP Precision: 1.0000\n",
      "MDP Recall: 0.1500\n",
      "MDP F1 Score: 0.2609\n",
      "MDP NDCG Score: 1.0000\n",
      "\n",
      "Q-Learning Accuracy: 0.2900\n",
      "Q-Learning Precision: 1.0000\n",
      "Q-Learning Recall: 0.2900\n",
      "Q-Learning F1 Score: 0.4496\n",
      "Q-Learning NDCG Score: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ndcg_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download NLTK dependencies\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Load MovieLens 1M Dataset (Larger Dataset)\n",
    "# -------------------------------\n",
    "MOVIELENS_URL = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "\n",
    "# Download the ZIP file in-memory\n",
    "response = requests.get(MOVIELENS_URL)\n",
    "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "\n",
    "# Read ratings.dat and movies.dat\n",
    "with zip_file.open(\"ml-1m/ratings.dat\") as file:\n",
    "    ratings = pd.read_csv(file, sep=\"::\", names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"], engine=\"python\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "with zip_file.open(\"ml-1m/movies.dat\") as file:\n",
    "    movies = pd.read_csv(file, sep=\"::\", names=[\"movieId\", \"title\", \"genres\"], engine=\"python\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Merge Ratings & Movies\n",
    "df = ratings.merge(movies, on=\"movieId\")\n",
    "\n",
    "# Convert userId & movieId to categorical codes\n",
    "df[\"userId\"] = df[\"userId\"].astype(\"category\").cat.codes\n",
    "df[\"movieId\"] = df[\"movieId\"].astype(\"category\").cat.codes\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Simulate User Click Data\n",
    "# -------------------------------\n",
    "df[\"click\"] = (df[\"rating\"] >= 4).astype(int)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Multi-Armed Bandit (MAB) with Upper Confidence Bound (UCB1)\n",
    "# -------------------------------\n",
    "class MultiArmedBandit:\n",
    "    def __init__(self, movie_ids):\n",
    "        self.movie_rewards = {movie_id: 0 for movie_id in movie_ids}\n",
    "        self.movie_attempts = {movie_id: 1 for movie_id in movie_ids}\n",
    "\n",
    "    def select_movie(self, num_recs=5):\n",
    "        selected_movies = sorted(\n",
    "            self.movie_rewards.keys(), \n",
    "            key=lambda movie: self.movie_rewards[movie] / self.movie_attempts[movie] + np.sqrt(2 * np.log(sum(self.movie_attempts.values())) / self.movie_attempts[movie]), \n",
    "            reverse=True\n",
    "        )\n",
    "        return selected_movies[:num_recs]\n",
    "\n",
    "    def update(self, movie_id, reward):\n",
    "        self.movie_attempts[movie_id] += 1\n",
    "        self.movie_rewards[movie_id] += reward\n",
    "\n",
    "mab = MultiArmedBandit(df[\"movieId\"].unique())\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Markov Decision Process (MDP) with More State Transitions\n",
    "# -------------------------------\n",
    "class MarkovDecisionProcess:\n",
    "    def __init__(self):\n",
    "        self.transitions = {}\n",
    "        self.rewards = {}\n",
    "\n",
    "    def update(self, current_movie, next_movie, reward):\n",
    "        key = (current_movie, next_movie)\n",
    "        if key not in self.transitions:\n",
    "            self.transitions[key] = 1\n",
    "            self.rewards[key] = reward\n",
    "        else:\n",
    "            self.transitions[key] += 1\n",
    "            self.rewards[key] = 0.9 * self.rewards[key] + 0.1 * reward\n",
    "\n",
    "    def recommend_next(self, current_movie, num_recs=5):\n",
    "        candidates = sorted(\n",
    "            [(key[1], self.rewards[key]) for key in self.rewards if key[0] == current_movie], \n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        return [movie for movie, _ in candidates[:num_recs]] if candidates else random.choices(df[\"movieId\"].unique(), k=num_recs)\n",
    "\n",
    "mdp = MarkovDecisionProcess()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Q-Learning with Enhanced Learning Rate & Discount Factor\n",
    "# -------------------------------\n",
    "class QLearningRecommender:\n",
    "    def __init__(self, num_movies, alpha=0.2, gamma=0.95, epsilon=0.2):\n",
    "        self.num_movies = num_movies\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = {}\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        key = (state, action)\n",
    "        if key not in self.q_table:\n",
    "            self.q_table[key] = 0\n",
    "        next_max = max([self.q_table.get((next_state, a), 0) for a in range(self.num_movies)], default=0)\n",
    "        self.q_table[key] = (1 - self.alpha) * self.q_table[key] + self.alpha * (reward + self.gamma * next_max)\n",
    "\n",
    "    def select_movie(self, state, num_recs=5):\n",
    "        return [\n",
    "            random.choice(range(self.num_movies))\n",
    "            if random.random() < self.epsilon\n",
    "            else max(range(self.num_movies), key=lambda x: self.q_table.get((state, x), 0))\n",
    "            for _ in range(num_recs)\n",
    "        ]\n",
    "\n",
    "q_learning = QLearningRecommender(df[\"movieId\"].nunique())\n",
    "\n",
    "# -------------------------------\n",
    "# Compare Accuracy & NDCG Score of Methods\n",
    "# -------------------------------\n",
    "def evaluate_recommendations(recommend_func, test_users, actual_clicks):\n",
    "    predictions = []\n",
    "    for user in test_users:\n",
    "        recommendations = recommend_func()\n",
    "        predictions.append(1 if any(movie in actual_clicks.get(user, []) for movie in recommendations) else 0)\n",
    "    return predictions\n",
    "\n",
    "test_users = df[\"userId\"].unique()[:100]\n",
    "actual_clicks = {user: df[(df[\"userId\"] == user) & (df[\"click\"] == 1)][\"movieId\"].tolist() for user in test_users}\n",
    "\n",
    "mab_preds = evaluate_recommendations(mab.select_movie, test_users, actual_clicks)\n",
    "mdp_preds = evaluate_recommendations(lambda: mdp.recommend_next(random.choice(df[\"movieId\"].unique()), 5), test_users, actual_clicks)\n",
    "ql_preds = evaluate_recommendations(lambda: q_learning.select_movie(random.choice(df[\"movieId\"].unique()), 5), test_users, actual_clicks)\n",
    "\n",
    "y_true = [1 if actual_clicks.get(user, []) else 0 for user in test_users]\n",
    "\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"{name} Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"{name} Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"{name} F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"{name} NDCG Score: {ndcg_score([y_true], [y_pred]):.4f}\\n\")\n",
    "\n",
    "print_metrics(\"MAB\", y_true, mab_preds)\n",
    "print_metrics(\"MDP\", y_true, mdp_preds)\n",
    "print_metrics(\"Q-Learning\", y_true, ql_preds)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIuzR+oxu22Fb10cnPgPRa",
   "provenance": [
    {
     "file_id": "1VpSyqkOmWsrnqH_5Kj8LuP4XSSR9ViTg",
     "timestamp": 1739987231618
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
